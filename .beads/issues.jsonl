{"id":"brain-19s","title":"Experiment/Feedback Framework Research","description":"Research existing frameworks for AI agent experiments with transcript review.\n\nLook for:\n- Agent evaluation tools\n- Transcript analysis\n- A/B testing prompts\n- Success metrics\n\nLater task - log for future research session.","status":"open","priority":2,"issue_type":"task","owner":"overnight-agent@brain","created_at":"2026-02-03T15:40:43.088982394-05:00","created_by":"Overnight Agent","updated_at":"2026-02-03T15:40:43.088982394-05:00","labels":["infrastructure","research"]}
{"id":"brain-2wz","title":"ML Pipeline Literature Coverage","description":"Assess coverage of ML pipeline options for arterial_analysis project. Cover: preprocessing, feature selection/extraction, model selection, validation, interpretability.","status":"open","priority":1,"issue_type":"task","owner":"overnight-agent@brain","created_at":"2026-02-03T17:49:30.386428353-05:00","created_by":"Overnight Agent","updated_at":"2026-02-03T17:49:30.386428353-05:00","labels":["arterial_analysis","research"]}
{"id":"brain-4aq","title":"Obsidian Note Pattern Analysis","description":"Analyze daily note usage patterns, find fill rates, propose optimized templates based on actual behavior.","status":"open","priority":2,"issue_type":"task","owner":"overnight-agent@brain","created_at":"2026-02-03T17:49:48.647564144-05:00","created_by":"Overnight Agent","updated_at":"2026-02-03T17:49:48.647564144-05:00","labels":["analysis","obsidian"]}
{"id":"brain-9ie","title":"Code Verification Workflow Design","description":"Create structured approach to verify Claude-generated code. Levels: quick/standard/deep. Include learning hooks and confidence markers.","status":"open","priority":2,"issue_type":"task","owner":"overnight-agent@brain","created_at":"2026-02-03T17:50:10.617877481-05:00","created_by":"Overnight Agent","updated_at":"2026-02-03T17:50:10.617877481-05:00","labels":["learning","workflow"]}
{"id":"brain-cka","title":"Skill: Scheduler Setup Guide","description":"Convert knowledge/guides/scheduler-setup.md into a proper skill at knowledge/skills/scheduler-setup.md with parameterized paths, auto-detection, and validation steps.","status":"open","priority":2,"issue_type":"task","owner":"overnight-agent@brain","created_at":"2026-02-03T17:41:30.525446836-05:00","created_by":"Overnight Agent","updated_at":"2026-02-03T17:41:30.525446836-05:00","labels":["infrastructure","skill"]}
{"id":"brain-djh","title":"NotebookLM Token-Efficient Upload Skill","description":"## Goal\nBuild a tool/script that facilitates identifying and uploading documents to NotebookLM - making it easy to feed in webpages, PDFs, docs without manual work.\n\n## Environment Constraints\n- **Execution env:** WSL2 Claude Code\n- **Depends on:** brain-qms (need source patterns first)\n- **Working dir:** ~/brain\n\n## What This Task Must Produce\n\n### 1. Upload Facilitator Script\nCreate tools/scripts/nlm-upload.py or .sh:\n```\nnlm-upload --notebook \u003cname\u003e --url \u003curl\u003e\nnlm-upload --notebook \u003cname\u003e --file \u003cpath\u003e\nnlm-upload --notebook \u003cname\u003e --text \u003cfile.md\u003e\nnlm-upload --notebook \u003cname\u003e --zotero \u003ccollection\u003e\n```\n\n### 2. Batch Upload Support\n- Accept list of URLs from file\n- Accept directory of PDFs\n- Progress reporting\n- Error handling with retry\n\n### 3. Integration with Registry\n- Auto-update notebooks.yaml after upload\n- Increment source_count\n- Update last_verified\n\n## Success Criteria\n- [ ] Script created and executable\n- [ ] Single upload works (url, file, text)\n- [ ] Batch upload works\n- [ ] Registry auto-updates\n\n## Depends On\n- brain-qms: Need to know source_add patterns\n- brain-jtj: Need registry system in place\n\n## Overnight Agent Instructions\n1. Read brain-qms output (source patterns)\n2. Read brain-jtj output (registry format)\n3. Build script with argparse\n4. Test each upload mode\n5. Add registry update logic","status":"open","priority":2,"issue_type":"task","owner":"overnight-agent@brain","created_at":"2026-02-03T15:40:40.392827234-05:00","created_by":"Overnight Agent","updated_at":"2026-02-03T16:05:47.457757482-05:00","labels":["notebooklm","skill"],"dependencies":[{"issue_id":"brain-djh","depends_on_id":"brain-qms","type":"blocks","created_at":"2026-02-03T16:12:44.423084605-05:00","created_by":"Overnight Agent"},{"issue_id":"brain-djh","depends_on_id":"brain-jtj","type":"blocks","created_at":"2026-02-03T16:12:46.337586759-05:00","created_by":"Overnight Agent"}]}
{"id":"brain-jtj","title":"NotebookLM Agent Query Tools","description":"## Goal\nCreate the tooling layer so agents can query NotebookLM efficiently without rediscovering notebook IDs each session.\n\n## Environment Constraints\n- **Execution env:** WSL2 or Windows Claude Code\n- **Depends on:** brain-qms (need source patterns documented first)\n- **Working dir:** ~/brain\n\n## What This Task Must Produce\n\n### 1. Notebook Registry System\nCreate ~/.config/notebooklm/notebooks.yaml:\n```yaml\nnotebooks:\n  \u003cname\u003e:\n    id: \u003cactual-uuid\u003e\n    description: \u003cwhat's in it\u003e\n    keywords: [list, of, trigger, words]\n    source_count: N\n    last_verified: YYYY-MM-DD\ndefault_notebook: \u003cname\u003e\n```\n\n### 2. Query Skill Document\nCreate knowledge/skills/notebooklm-query.md:\n- How to load registry\n- How to match query to notebook\n- How to call notebook_query\n- How to format response with citations\n\n### 3. Upload Skill Document  \nCreate knowledge/skills/notebooklm-upload.md:\n- Patterns from brain-qms findings\n- Decision tree: URL vs file vs text\n- Error handling\n\n## Success Criteria\n- [ ] Registry file created with all existing notebooks\n- [ ] Query skill document written\n- [ ] Upload skill document written\n- [ ] Test: Load registry, query a notebook, get answer\n\n## Overnight Agent Instructions\n1. Call notebook_list to get all notebooks\n2. Build registry YAML with actual IDs\n3. Write query skill based on working patterns\n4. Write upload skill based on brain-qms findings\n5. Test the workflow end-to-end","status":"open","priority":2,"issue_type":"task","owner":"overnight-agent@brain","created_at":"2026-02-03T15:19:44.316773869-05:00","created_by":"Overnight Agent","updated_at":"2026-02-03T16:04:42.16565227-05:00","labels":["infrastructure","notebooklm","tools"],"dependencies":[{"issue_id":"brain-jtj","depends_on_id":"brain-qms","type":"blocks","created_at":"2026-02-03T15:19:44.318171589-05:00","created_by":"Overnight Agent"}]}
{"id":"brain-pmj","title":"Skill: Standardized Task Creator","description":"## Goal\nCreate a skill that generates properly-specified tasks in both bd AND scheduler format, so future task creation is standardized.\n\n## Environment Constraints\n- **Execution env:** WSL2 Claude Code\n- **Working dir:** ~/brain\n- **References:** knowledge/skills/task-specification.md (existing template)\n\n## What This Task Must Produce\n\n### 1. Task Creator Skill Document\nCreate knowledge/skills/task-creator.md that defines:\n\n**Input template (what user provides):**\n- Goal (1-2 sentences)\n- Environment hints (where it runs, what tools needed)\n- Known blockers (if any)\n- Dependencies (other bead IDs)\n\n**Output (what skill produces):**\n- bd create command with full spec\n- tasks/pending/NNN-name.md file content\n- Both linked via bead_id field\n\n### 2. Task Spec Template\nCreate tasks/templates/task-template.md:\n```yaml\n---\nname: \npriority: \nestimated_tokens: \nmode: [autonomous|plan-first]\nskill: \nmodel_hint: \ntags: []\ndepends_on: []\nbead_id: \n---\n# Title\n\n## Goal\n## Environment Constraints  \n## What This Task Must Produce\n## Success Criteria\n## Overnight Agent Instructions\n```\n\n### 3. BD Integration Pattern\nDocument how bd and scheduler should sync:\n- bd is source of truth\n- Scheduler task files reference bead_id\n- When bead closes, scheduler task moves to completed\n\n## Success Criteria\n- [ ] Task creator skill document complete\n- [ ] Template file created\n- [ ] Integration pattern documented\n- [ ] Test: Use skill to create one new task\n\n## Overnight Agent Instructions\n1. Read existing task-specification.md\n2. Read good examples: 020-notebooklm-library-pipeline.md\n3. Extract the pattern into reusable skill\n4. Create template file\n5. Document bdâ†”scheduler sync pattern","status":"open","priority":2,"issue_type":"task","owner":"overnight-agent@brain","created_at":"2026-02-03T15:40:37.419610934-05:00","created_by":"Overnight Agent","updated_at":"2026-02-03T16:05:16.07988536-05:00","labels":["infrastructure","skill"]}
{"id":"brain-qms","title":"NotebookLM Library Pipeline","description":"## Goal\nBuild NotebookLM into a powerful knowledge layer that agents can use without loading content into context.\n\n## Environment Constraints\n- **Execution env:** WSL2 Claude Code with NotebookLM MCP\n- **Auth:** RESOLVED - uses Windows auth via NOTEBOOKLM_MCP_CLI_PATH\n- **MCP tools available:** notebook_create, notebook_list, source_add, notebook_query\n- **Working dir:** ~/brain\n\n## What This Task Must Produce\n\n### 1. Document the source_add patterns\nTest and document how to add:\n- URLs (web documentation)\n- File paths (PDFs from Zotero, local files)\n- Raw text (Obsidian note exports)\n\n### 2. Create test notebook\n- Create 'system-test' notebook\n- Add 1 URL source (e.g., pycaret docs page)\n- Add 1 text source (sample content)\n- Verify query returns grounded answer\n\n### 3. Document failure modes\n- What happens with large files?\n- What happens with invalid URLs?\n- What are the rate limits?\n\n## Success Criteria\n- [ ] source_add patterns documented with working examples\n- [ ] Test notebook created and queryable\n- [ ] Failure modes documented\n- [ ] Output written to knowledge/tools/notebooklm-source-patterns.md\n\n## This is NOT\n- Setting up your actual research notebooks (that needs your input on what to include)\n- Building the full registry system (that's brain-jtj)\n\n## Overnight Agent Instructions\n1. List existing notebooks first\n2. Create 'system-test' notebook\n3. Test each source_add pattern\n4. Document what works and what fails\n5. Clean up test notebook if desired","status":"open","priority":2,"issue_type":"task","owner":"overnight-agent@brain","created_at":"2026-02-03T15:19:32.814567187-05:00","created_by":"Overnight Agent","updated_at":"2026-02-03T16:04:08.360806169-05:00","labels":["infrastructure","notebooklm"],"dependencies":[{"issue_id":"brain-qms","depends_on_id":"brain-zpd","type":"blocks","created_at":"2026-02-03T15:19:32.820347342-05:00","created_by":"Overnight Agent"}]}
{"id":"brain-zpd","title":"NotebookLM Auth: WSL Cookie Bridge","description":"## Goal\nEnable reliable NotebookLM MCP auth that doesn't expire every few minutes.\n\n## Root Cause Analysis (CONFIRMED)\n1. **Google cookie rotation:** SIDCC, __Secure-*PSIDTS cookies rotate every ~10-30 minutes\n2. **MCP stores static snapshot:** Saved cookies don't auto-update\n3. **Recovery needs Chrome:** run_headless_auth() can refresh but needs Chrome browser\n4. **WSL can't run Chrome:** Headless recovery path fails\n\nThe error at base.py:600-603 triggers when NotebookLM redirects to accounts.google.com.\n\n## Environment\n- **Execution env:** WSL2 - NO browser available\n- **MCP location:** /home/div/.local/share/uv/tools/notebooklm-mcp-cli/\n- **Auth storage:** ~/.notebooklm-mcp-cli/profiles/default/\n\n## Proposed Solutions (Priority Order)\n\n### Solution A: Run MCP on Windows side (RECOMMENDED)\n- NotebookLM MCP runs in Claude Desktop (Windows)\n- Headless Chrome refresh works natively on Windows\n- No WSL bridging needed\n- **Action:** Configure Claude Desktop MCP, not Claude Code MCP\n\n### Solution B: Scheduled Windows Cookie Export\n- Windows Task Scheduler runs cookie export script\n- Saves to /mnt/c/Users/din18/.nlm-cookies.txt\n- Cron job in WSL runs: nlm login --manual -f \u003cfile\u003e\n- **Frequency:** Every 5-10 minutes (matches Google rotation)\n- **Con:** High overhead, still may have gaps\n\n### Solution C: Keep Chrome Running with CDP\n- Run Chrome on Windows with --remote-debugging-port\n- WSL connects via localhost to Chrome DevTools\n- Cookies stay fresh as long as Chrome is open\n- **Con:** Chrome must stay open\n\n## Success Criteria\n- [ ] notebook_list works without auth error\n- [ ] Auth persists for at least 1 hour without intervention\n- [ ] Solution documented with exact steps\n\n## Investigation Steps\n1. Check if NotebookLM MCP is configured in Claude Desktop (Windows)\n2. If yes, test if it works there (headless refresh should work)\n3. If no, add it and test\n4. Document working configuration","status":"closed","priority":2,"issue_type":"task","owner":"overnight-agent@brain","created_at":"2026-02-03T15:19:19.444616142-05:00","created_by":"Overnight Agent","updated_at":"2026-02-03T15:32:36.309564154-05:00","closed_at":"2026-02-03T15:32:36.309564154-05:00","close_reason":"RESOLVED: WSL uses Windows auth via NOTEBOOKLM_MCP_CLI_PATH=/mnt/c/Users/din18/.notebooklm-mcp-cli in ~/.claude.json. Windows headless Chrome refreshes auth, both platforms share same source.","labels":["infrastructure","notebooklm"]}
